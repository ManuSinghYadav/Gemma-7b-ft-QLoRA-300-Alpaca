# Gemma-7b-ft-QLoRA-300-Alpaca
This project involves fine-tuning Google's [Gemma-7B](https://huggingface.co/google/gemma-7b) LLM. The dataset used for this fine-tuning is the [Alpaca cleaned dataset](https://huggingface.co/datasets/yahma/alpaca-cleaned) originally released by Stanford University. Due to resource limitations, only 300 rows from the dataset were used for fine-tuning.

After fine-tuning, the model was pushed/saved to the Hugging Face hub, which can be viewed [here](https://huggingface.co/msinghy/Gemma-7b-ft-QLoRA-300-Alpaca).
